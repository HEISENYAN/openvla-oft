Sun Aug 17 00:40:32 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:D1:00.0 Off |                    0 |
| N/A   32C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-17 00:40:44.027607: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-17 00:40:44.197201: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-17 00:40:44.197347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-17 00:40:44.223666: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-17 00:40:44.282258: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-17 00:40:46.943870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 14
  PROPRIO_DIM = 14
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-17 00:40:58.638917: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Instantiating pretrained VLA policy...
Warning: No config.json found at /home/congcong/yanzhengyang/aloha_adjust_bottle_100000/config.json

------------------------------------------------------------------------------------------------
No modeling_prismatic.py found in checkpoint directory.
Copied current version from: ./prismatic/extern/hf/modeling_prismatic.py
To checkpoint location: /home/congcong/yanzhengyang/aloha_adjust_bottle_100000/modeling_prismatic.py
------------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------------
No configuration_prismatic.py found in checkpoint directory.
Copied current version from: ./prismatic/extern/hf/configuration_prismatic.py
To checkpoint location: /home/congcong/yanzhengyang/aloha_adjust_bottle_100000/configuration_prismatic.py
------------------------------------------------------------------------------------------------

Traceback (most recent call last):
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/deploy.py", line 156, in <module>
    deploy()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/deploy.py", line 151, in deploy
    server = OpenVLAServer(cfg)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/deploy.py", line 55, in __init__
    self.vla = get_vla(cfg)
  File "/home/congcong/yanzhengyang/openvla-oft/experiments/robot/openvla_utils.py", line 282, in get_vla
    vla = AutoModelForVision2Seq.from_pretrained(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 523, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 928, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/transformers/utils/hub.py", line 369, in cached_file
    raise EnvironmentError(
OSError: /home/congcong/yanzhengyang/aloha_adjust_bottle_100000 does not appear to have a file named config.json. Checkout 'https://huggingface.co//home/congcong/yanzhengyang/aloha_adjust_bottle_100000/tree/None' for available files.
Sun Aug 17 00:43:35 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:D1:00.0 Off |                    0 |
| N/A   32C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-17 00:43:39.728561: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-17 00:43:39.762293: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-17 00:43:39.762319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-17 00:43:39.763558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-17 00:43:39.769106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-17 00:43:40.859106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 14
  PROPRIO_DIM = 14
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-17 00:43:46.006875: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Instantiating pretrained VLA policy...
Created backup of original config at: /home/congcong/yanzhengyang/aloha_adjust_bottle_100000/config.json.back.20250817_004355
Updated config.json at: /home/congcong/yanzhengyang/aloha_adjust_bottle_100000/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.68it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.57it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  3.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  4.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]
INFO:     Started server process [3746765]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8777 (Press CTRL+C to quit)
INFO:     10.22.4.13:42628 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:39582 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58766 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58780 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58796 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58798 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58806 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58816 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58830 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58838 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58850 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58852 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58868 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58870 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58872 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58886 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58890 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58894 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58908 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58914 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58924 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58936 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58940 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58946 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58958 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58970 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58974 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:58990 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59000 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59004 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59008 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59014 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59022 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59024 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59038 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59044 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59060 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59066 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59068 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59072 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59082 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59092 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59106 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59122 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59134 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59138 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:59148 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49260 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49272 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49274 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49284 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49294 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49296 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49298 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49312 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49322 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49332 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49340 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49356 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49370 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49382 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49398 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49412 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49418 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49426 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49428 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49438 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49440 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49452 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49458 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49466 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49476 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49480 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49490 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49494 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49510 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49518 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49524 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49530 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49546 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49550 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49566 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49582 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49590 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49596 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49602 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49614 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49628 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49642 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49654 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49664 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49668 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49676 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49684 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49688 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49696 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49710 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49712 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49722 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49726 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49728 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49874 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49884 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49888 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49898 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49914 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49926 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49928 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49932 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49944 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49948 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49954 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49964 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49972 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49984 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49990 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:49996 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50012 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50018 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50026 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50038 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50050 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50064 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50078 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50088 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50102 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50116 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50120 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50128 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50130 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50136 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50140 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50148 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50152 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50154 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50166 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50174 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50184 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50198 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50208 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50216 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50228 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50238 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50242 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50252 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50266 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50276 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50284 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50300 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50312 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50320 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50324 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50338 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50352 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50366 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50374 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50384 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:50400 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45732 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45748 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45758 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45764 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45772 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45782 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45788 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45798 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45812 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45828 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45830 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45838 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45840 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45842 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45850 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45860 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45862 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45876 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45892 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45894 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45908 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45922 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45934 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45936 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45942 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45954 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45960 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45974 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45984 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:45996 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46000 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46016 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46028 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46032 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46036 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46052 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46068 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46080 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46090 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46098 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46114 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46130 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46144 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46152 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46166 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46182 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46196 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46204 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46208 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46210 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46224 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46240 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46256 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46262 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46264 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46268 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46910 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46916 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46918 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46924 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46940 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46956 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46966 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46976 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46982 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46992 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:46994 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47006 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47020 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47036 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47046 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47048 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47058 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47064 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47074 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47088 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47098 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47108 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47110 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47126 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47140 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47144 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47148 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47158 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47172 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47180 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47190 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47194 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47208 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47222 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47234 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47238 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47242 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47248 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47252 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47256 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47268 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47278 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47280 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47290 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47300 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47304 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47316 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47318 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47322 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47332 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47348 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47352 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47358 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47368 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47376 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47386 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:47400 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34272 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34276 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34292 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34296 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34308 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34314 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34324 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34340 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34352 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34356 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34372 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34374 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34382 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34390 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34396 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34406 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34410 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34420 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34426 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34434 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34444 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34448 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34462 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34464 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34470 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34474 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34476 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34478 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34492 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34494 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34510 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34514 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34524 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34534 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34536 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:34544 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:51950 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:51960 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:51976 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:51986 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:51998 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52008 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52016 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52030 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52042 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52058 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52068 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52082 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52088 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38578 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38584 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38586 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38594 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38606 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38614 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38626 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38640 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38654 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38668 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38670 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38678 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38694 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38702 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38712 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38724 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38736 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38740 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38756 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38760 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38770 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38782 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38784 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38796 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:38810 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52256 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52266 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52268 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52284 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52296 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52306 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52318 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52328 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52334 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52346 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52362 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52372 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52388 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52392 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52406 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52412 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52424 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52428 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52440 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52444 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52448 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52460 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52472 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52486 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52496 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52510 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:52522 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53682 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53690 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53692 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53704 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53708 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53714 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53730 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53746 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53756 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53772 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53776 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53786 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53794 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53800 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53804 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53816 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53832 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53840 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53854 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53864 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53866 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53872 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53876 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53882 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53886 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:53902 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54248 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54258 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54274 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54288 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54302 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54316 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54328 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54342 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54352 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54364 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54368 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54372 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54382 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54392 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54402 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54414 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54422 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54426 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54432 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54444 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54446 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:54458 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33008 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33018 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33022 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33024 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33036 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33050 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33060 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33062 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33068 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33074 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33084 - "POST /act HTTP/1.1" 200 OK
INFO:     10.22.4.13:33090 - "POST /act HTTP/1.1" 200 OK
slurmstepd: error: *** JOB 263121 ON dgx-15 CANCELLED AT 2025-08-17T01:22:18 ***
Thu Aug 21 01:31:46 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.158.01             Driver Version: 570.158.01     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H800                    On  |   00000000:9D:00.0 Off |          N/A   31C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 01:31:58.356309: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 2025-08-21 01:31:58.538064: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:31:58.538190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:31:58.567536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:31:58.628737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:32:01.218166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
 variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:32:00.632233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:32:00.632233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:32:00.632233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:32:00.632233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:32:00.632277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:32:00.632280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:32:00.632284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:32:00.632357: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:32:00.655740: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:32:00.655743: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:32:00.655746: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:32:00.655745: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:32:00.707683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:32:00.707682: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:32:00.707683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:32:00.707684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
 TF-TRT Warning: Could not find TensorRT
2025-08-21 01:32:03.450182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-08-21 01:32:03.468293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
                                                                                                                                                                                                                                                                   Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
nts:  NUM_ACTIONS_CHUNK = 25

Using ALOHA constants:  ACTION_DIM = 7  NUM_ACTIONS_CHUNK = 25


  PROPRIO_DIM = 7  NUM_ACTIONS_CHUNK = 25  ACTION_DIM = 7



  ACTION_DIM = 7  PROPRIO_DIM = 7  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds  NUM_ACTIONS_CHUNK = 25



  PROPRIO_DIM = 7If needed, manually set the correct constants in `prismatic/vla/constants.py`!  ACTION_DIM = 7

  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds

  PROPRIO_DIM = 7  ACTION_PROPRIO_NORMALIZATION_TYPE = boundsIf needed, manually set the correct constants in `prismatic/vla/constants.py`!


If needed, manually set the correct constants in `prismatic/vla/constants.py`!  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds

If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 01:32:16.057409: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.058704: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.060261: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.064257: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.064405: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.066909: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.068372: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.069799: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.071142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.071143: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.071735: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.072251: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.072853: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.073342: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.073910: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:32:16.074981: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`

Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: boundsDetected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_013226-emksfeg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/emksfeg2
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files:  39%|███▉      | 7/18 [01:04<01:45,  9.56s/it]Fetching 18 files:  44%|████▍     | 8/18 [01:04<01:19,  7.97s/it]Fetching 18 files: 100%|██████████| 18/18 [01:04<00:00,  3.59s/it]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_013329
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"

------------------------------------------------------------------------------------------------
Found mismatch between:
Current:   ./prismatic/extern/hf/modeling_prismatic.py
Checkpoint: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py

Created backup of original checkpoint file at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py.back.20250821_013329
Copied current version to checkpoint at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/modeling_prismatic.py
Changes complete. The checkpoint will now use the current version of modeling_prismatic.py
------------------------------------------------------------------------------------------------

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.08it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            # trainable params in action_head: 151117831
# total trainable params: 261946119
Traceback (most recent call last):
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
    finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune
    train_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
    _, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 202, in make_dataset_from_rlds
    builder = tfds.builder(name, data_dir=data_dir)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py", line 166, in __call__
    return function(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 215, in builder
    raise not_found_error
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 196, in builder
    cls = builder_cls(str(name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 121, in builder_cls
    cls = registered.imported_builder_cls(str(ds_name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py", line 301, in imported_builder_cls
    raise DatasetNotFoundError(f'Dataset {name} not found.')
tensorflow_datasets.core.registered.DatasetNotFoundError: Dataset aloha_game not found.
Available datasets:
	- abstract_reasoning
	- accentdb
	- aeslc
	- aflw2k3d
	- ag_news_subset
	- ai2_arc
	- ai2_arc_with_ir
	- amazon_us_reviews
	- anli
	- answer_equivalence
	- arc
	- asqa
	- asset
	- assin2
	- bair_robot_pushing_small
	- bccd
	- beans
	- bee_dataset
	- beir
	- big_patent
	- bigearthnet
	- billsum
	- binarized_mnist
	- binary_alpha_digits
	- ble_wind_field
	- blimp
	- booksum
	- bool_q
	- bot_adversarial_dialogue
	- bucc
	- c4
	- c4_wsrs
	- caltech101
	- caltech_birds2010
	- caltech_birds2011
	- cardiotox
	- cars196
	- cassava
	- cats_vs_dogs
	- celeb_a
	- celeb_a_hq
	- cfq
	- cherry_blossoms
	- chexpert
	- cifar10
	- cifar100
	- cifar100_n
	- cifar10_1
	- cifar10_corrupted
	- cifar10_h
	- cifar10_n
	- citrus_leaves
	- cityscapes
	- civil_comments
	- clevr
	- clic
	- clinc_oos
	- cmaterdb
	- cnn_dailymail
	- coco
	- coco_captions
	- coil100
	- colorectal_histology
	- colorectal_histology_large
	- common_voice
	- conll2002
	- conll2003
	- controlled_noisy_web_labels
	- coqa
	- corr2cause
	- cos_e
	- cosmos_qa
	- covid19
	- covid19sum
	- crema_d
	- criteo
	- cs_restaurants
	- curated_breast_imaging_ddsm
	- cycle_gan
	- d4rl_adroit_door
	- d4rl_adroit_hammer
	- d4rl_adroit_pen
	- d4rl_adroit_relocate
	- d4rl_antmaze
	- d4rl_mujoco_ant
	- d4rl_mujoco_halfcheetah
	- d4rl_mujoco_hopper
	- d4rl_mujoco_walker2d
	- dart
	- databricks_dolly
	- davis
	- deep1b
	- deep_weeds
	- definite_pronoun_resolution
	- dementiabank
	- diabetic_retinopathy_detection
	- diamonds
	- div2k
	- dmlab
	- doc_nli
	- dolphin_number_word
	- domainnet
	- downsampled_imagenet
	- drop
	- dsprites
	- dtd
	- duke_ultrasound
	- e2e_cleaned
	- efron_morris75
	- emnist
	- eraser_multi_rc
	- esnli
	- eurosat
	- fashion_mnist
	- flic
	- flores
	- food101
	- forest_fires
	- fuss
	- gap
	- geirhos_conflict_stimuli
	- gem
	- genomics_ood
	- german_credit_numeric
	- gigaword
	- glove100_angular
	- glue
	- goemotions
	- gov_report
	- gpt3
	- gref
	- groove
	- grounded_scan
	- gsm8k
	- gtzan
	- gtzan_music_speech
	- hellaswag
	- higgs
	- hillstrom
	- horses_or_humans
	- howell
	- i_naturalist2017
	- i_naturalist2018
	- i_naturalist2021
	- imagenet2012
	- imagenet2012_corrupted
	- imagenet2012_fewshot
	- imagenet2012_multilabel
	- imagenet2012_real
	- imagenet2012_subset
	- imagenet_a
	- imagenet_lt
	- imagenet_pi
	- imagenet_r
	- imagenet_resized
	- imagenet_sketch
	- imagenet_v2
	- imagenette
	- imagewang
	- imdb_reviews
	- irc_disentanglement
	- iris
	- istella
	- kddcup99
	- kitti
	- kmnist
	- laion400m
	- lambada
	- lfw
	- librispeech
	- librispeech_lm
	- libritts
	- ljspeech
	- lm1b
	- locomotion
	- lost_and_found
	- lsun
	- lvis
	- malaria
	- math_dataset
	- math_qa
	- mctaco
	- media_sum
	- mlqa
	- mnist
	- mnist_corrupted
	- movie_lens
	- movie_rationales
	- movielens
	- moving_mnist
	- mrqa
	- mslr_web
	- mt_opt
	- mtnt
	- multi_news
	- multi_nli
	- multi_nli_mismatch
	- natural_instructions
	- natural_questions
	- natural_questions_open
	- newsroom
	- nsynth
	- nyu_depth_v2
	- ogbg_molpcba
	- omniglot
	- open_images_challenge2019_detection
	- open_images_v4
	- openbookqa
	- opinion_abstracts
	- opinosis
	- opus
	- oxford_flowers102
	- oxford_iiit_pet
	- para_crawl
	- pass
	- patch_camelyon
	- paws_wiki
	- paws_x_wiki
	- penguins
	- pet_finder
	- pg19
	- piqa
	- places365_small
	- placesfull
	- plant_leaves
	- plant_village
	- plantae_k
	- protein_net
	- q_re_cc
	- qa4mre
	- qasc
	- quac
	- quality
	- quickdraw_bitmap
	- race
	- radon
	- real_toxicity_prompts
	- reddit
	- reddit_disentanglement
	- reddit_tifu
	- ref_coco
	- resisc45
	- rlu_atari
	- rlu_atari_checkpoints
	- rlu_atari_checkpoints_ordered
	- rlu_control_suite
	- rlu_dmlab_explore_object_rewards_few
	- rlu_dmlab_explore_object_rewards_many
	- rlu_dmlab_rooms_select_nonmatching_object
	- rlu_dmlab_rooms_watermaze
	- rlu_dmlab_seekavoid_arena01
	- rlu_locomotion
	- rlu_rwrl
	- robomimic_mg
	- robomimic_mh
	- robomimic_ph
	- robonet
	- robosuite_panda_pick_place_can
	- rock_paper_scissors
	- rock_you
	- s3o4d
	- salient_span_wikipedia
	- samsum
	- savee
	- scan
	- scene_parse150
	- schema_guided_dialogue
	- sci_tail
	- scicite
	- scientific_papers
	- scrolls
	- segment_anything
	- sentiment140
	- shapes3d
	- sift1m
	- simpte
	- siscore
	- smallnorb
	- smartwatch_gestures
	- snli
	- so2sat
	- speech_commands
	- spoken_digit
	- squad
	- squad_question_generation
	- stanford_dogs
	- stanford_online_products
	- star_cfq
	- starcraft_video
	- stl10
	- story_cloze
	- summscreen
	- sun397
	- super_glue
	- svhn_cropped
	- symmetric_solids
	- tao
	- tatoeba
	- ted_hrlr_translate
	- ted_multi_translate
	- tedlium
	- tf_flowers
	- the300w_lp
	- tiny_shakespeare
	- titanic
	- trec
	- trivia_qa
	- tydi_qa
	- uc_merced
	- ucf101
	- unified_qa
	- universal_dependencies
	- unnatural_instructions
	- user_libri_audio
	- user_libri_text
	- vctk
	- visual_domain_decathlon
	- voc
	- voxceleb
	- voxforge
	- waymo_open_dataset
	- web_graph
	- web_nlg
	- web_questions
	- webvid
	- wider_face
	- wiki40b
	- wiki_auto
	- wiki_bio
	- wiki_dialog
	- wiki_table_questions
	- wiki_table_text
	- wikiann
	- wikihow
	- wikipedia
	- wikipedia_toxicity_subtypes
	- wine_quality
	- winogrande
	- wit
	- wit_kaggle
	- wmt13_translate
	- wmt14_translate
	- wmt15_translate
	- wmt16_translate
	- wmt17_translate
	- wmt18_translate
	- wmt19_translate
	- wmt_t2t_translate
	- wmt_translate
	- wordnet
	- wsc273
	- xnli
	- xquad
	- xsum
	- xtreme_pawsx
	- xtreme_pos
	- xtreme_s
	- xtreme_xnli
	- yahoo_ltrc
	- yelp_polarity_reviews
	- yes_no
	- youtube_vis

Check that:
    - if dataset was added recently, it may only be available
      in `tfds-nightly`
    - the dataset name is spelled correctly
    - dataset class defines all base class abstract methods
    - the module defining the dataset class is imported

The builder directory /congcong/tensorflow_datasets/aloha_game doesn't contain any versions.
No builder could be found in the directory: /congcong/tensorflow_datasets for the builder: aloha_game.
No registered data_dirs were found in:
	- /congcong/tensorflow_datasets

[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state[0m at: [34mhttps://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/xu3wjz4m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250821_013223-xu3wjz4m/logs[0m
[2025-08-21 01:34:23,146] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1278528) of binary: /home/congcong/miniconda3/envs/openvla-oft/bin/python3.10
Traceback (most recent call last):
  File "/home/congcong/miniconda3/envs/openvla-oft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
vla-scripts/finetune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-21_01:34:23
  host      : dgx-15.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1278528)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# trainable params in action_head: 151117831
# trainable params in action_head: 151117831
# trainable params in action_head: 151117831
# total trainable params: 261946119
# total trainable params: 261946119
# total trainable params: 261946119
# total trainable params: 261946119
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
        finetune()
finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
        response = fn(cfg, *args, **kwargs)    response = fn(cfg, *args, **kwargs)
response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune

  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune
    train_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    train_dataset = RLDSDataset(
      File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
train_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)    
self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset

  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
            _, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)_, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)_, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)


  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 202, in make_dataset_from_rlds
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 202, in make_dataset_from_rlds
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 202, in make_dataset_from_rlds
    builder = tfds.builder(name, data_dir=data_dir)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    builder = tfds.builder(name, data_dir=data_dir)
      File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
builder = tfds.builder(name, data_dir=data_dir)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
            return func(*args, **kwds)return func(*args, **kwds)return func(*args, **kwds)


  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py", line 166, in __call__
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py", line 166, in __call__
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py", line 166, in __call__
            return function(*args, **kwargs)return function(*args, **kwargs)return function(*args, **kwargs)


  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 215, in builder
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 215, in builder
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 215, in builder
    raise not_found_error        
raise not_found_errorraise not_found_error  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 196, in builder


  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 196, in builder
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 196, in builder
    cls = builder_cls(str(name))    
cls = builder_cls(str(name))  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner

  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    cls = builder_cls(str(name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 121, in builder_cls
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 121, in builder_cls
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 121, in builder_cls
    cls = registered.imported_builder_cls(str(ds_name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py", line 301, in imported_builder_cls
    cls = registered.imported_builder_cls(str(ds_name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py", line 301, in imported_builder_cls
    cls = registered.imported_builder_cls(str(ds_name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py", line 301, in imported_builder_cls
            raise DatasetNotFoundError(f'Dataset {name} not found.')raise DatasetNotFoundError(f'Dataset {name} not found.')raise DatasetNotFoundError(f'Dataset {name} not found.')


tensorflow_datasets.core.registeredtensorflow_datasets.core.registeredtensorflow_datasets.core.registered...DatasetNotFoundErrorDatasetNotFoundErrorDatasetNotFoundError: : : Dataset aloha_game not found.
Available datasets:
	- abstract_reasoning
	- accentdb
	- aeslc
	- aflw2k3d
	- ag_news_subset
	- ai2_arc
	- ai2_arc_with_ir
	- amazon_us_reviews
	- anli
	- answer_equivalence
	- arc
	- asqa
	- asset
	- assin2
	- bair_robot_pushing_small
	- bccd
	- beans
	- bee_dataset
	- beir
	- big_patent
	- bigearthnet
	- billsum
	- binarized_mnist
	- binary_alpha_digits
	- ble_wind_field
	- blimp
	- booksum
	- bool_q
	- bot_adversarial_dialogue
	- bucc
	- c4
	- c4_wsrs
	- caltech101
	- caltech_birds2010
	- caltech_birds2011
	- cardiotox
	- cars196
	- cassava
	- cats_vs_dogs
	- celeb_a
	- celeb_a_hq
	- cfq
	- cherry_blossoms
	- chexpert
	- cifar10
	- cifar100
	- cifar100_n
	- cifar10_1
	- cifar10_corrupted
	- cifar10_h
	- cifar10_n
	- citrus_leaves
	- cityscapes
	- civil_comments
	- clevr
	- clic
	- clinc_oos
	- cmaterdb
	- cnn_dailymail
	- coco
	- coco_captions
	- coil100
	- colorectal_histology
	- colorectal_histology_large
	- common_voice
	- conll2002
	- conll2003
	- controlled_noisy_web_labels
	- coqa
	- corr2cause
	- cos_e
	- cosmos_qa
	- covid19
	- covid19sum
	- crema_d
	- criteo
	- cs_restaurants
	- curated_breast_imaging_ddsm
	- cycle_gan
	- d4rl_adroit_door
	- d4rl_adroit_hammer
	- d4rl_adroit_pen
	- d4rl_adroit_relocate
	- d4rl_antmaze
	- d4rl_mujoco_ant
	- d4rl_mujoco_halfcheetah
	- d4rl_mujoco_hopper
	- d4rl_mujoco_walker2d
	- dart
	- databricks_dolly
	- davis
	- deep1b
	- deep_weeds
	- definite_pronoun_resolution
	- dementiabank
	- diabetic_retinopathy_detection
	- diamonds
	- div2k
	- dmlab
	- doc_nli
	- dolphin_number_word
	- domainnet
	- downsampled_imagenet
	- drop
	- dsprites
	- dtd
	- duke_ultrasound
	- e2e_cleaned
	- efron_morris75
	- emnist
	- eraser_multi_rc
	- esnli
	- eurosat
	- fashion_mnist
	- flic
	- flores
	- food101
	- forest_fires
	- fuss
	- gap
	- geirhos_conflict_stimuli
	- gem
	- genomics_ood
	- german_credit_numeric
	- gigaword
	- glove100_angular
	- glue
	- goemotions
	- gov_report
	- gpt3
	- gref
	- groove
	- grounded_scan
	- gsm8k
	- gtzan
	- gtzan_music_speech
	- hellaswag
	- higgs
	- hillstrom
	- horses_or_humans
	- howell
	- i_naturalist2017
	- i_naturalist2018
	- i_naturalist2021
	- imagenet2012
	- imagenet2012_corrupted
	- imagenet2012_fewshot
	- imagenet2012_multilabel
	- imagenet2012_real
	- imagenet2012_subset
	- imagenet_a
	- imagenet_lt
	- imagenet_pi
	- imagenet_r
	- imagenet_resized
	- imagenet_sketch
	- imagenet_v2
	- imagenette
	- imagewang
	- imdb_reviews
	- irc_disentanglement
	- iris
	- istella
	- kddcup99
	- kitti
	- kmnist
	- laion400m
	- lambada
	- lfw
	- librispeech
	- librispeech_lm
	- libritts
	- ljspeech
	- lm1b
	- locomotion
	- lost_and_found
	- lsun
	- lvis
	- malaria
	- math_dataset
	- math_qa
	- mctaco
	- media_sum
	- mlqa
	- mnist
	- mnist_corrupted
	- movie_lens
	- movie_rationales
	- movielens
	- moving_mnist
	- mrqa
	- mslr_web
	- mt_opt
	- mtnt
	- multi_news
	- multi_nli
	- multi_nli_mismatch
	- natural_instructions
	- natural_questions
	- natural_questions_open
	- newsroom
	- nsynth
	- nyu_depth_v2
	- ogbg_molpcba
	- omniglot
	- open_images_challenge2019_detection
	- open_images_v4
	- openbookqa
	- opinion_abstracts
	- opinosis
	- opus
	- oxford_flowers102
	- oxford_iiit_pet
	- para_crawl
	- pass
	- patch_camelyon
	- paws_wiki
	- paws_x_wiki
	- penguins
	- pet_finder
	- pg19
	- piqa
	- places365_small
	- placesfull
	- plant_leaves
	- plant_village
	- plantae_k
	- protein_net
	- q_re_cc
	- qa4mre
	- qasc
	- quac
	- quality
	- quickdraw_bitmap
	- race
	- radon
	- real_toxicity_prompts
	- reddit
	- reddit_disentanglement
	- reddit_tifu
	- ref_coco
	- resisc45
	- rlu_atari
	- rlu_atari_checkpoints
	- rlu_atari_checkpoints_ordered
	- rlu_control_suite
	- rlu_dmlab_explore_object_rewards_few
	- rlu_dmlab_explore_object_rewards_many
	- rlu_dmlab_rooms_select_nonmatching_object
	- rlu_dmlab_rooms_watermaze
	- rlu_dmlab_seekavoid_arena01
	- rlu_locomotion
	- rlu_rwrl
	- robomimic_mg
	- robomimic_mh
	- robomimic_ph
	- robonet
	- robosuite_panda_pick_place_can
	- rock_paper_scissors
	- rock_you
	- s3o4d
	- salient_span_wikipedia
	- samsum
	- savee
	- scan
	- scene_parse150
	- schema_guided_dialogue
	- sci_tail
	- scicite
	- scientific_papers
	- scrolls
	- segment_anything
	- sentiment140
	- shapes3d
	- sift1m
	- simpte
	- siscore
	- smallnorb
	- smartwatch_gestures
	- snli
	- so2sat
	- speech_commands
	- spoken_digit
	- squad
	- squad_question_generation
	- stanford_dogs
	- stanford_online_products
	- star_cfq
	- starcraft_video
	- stl10
	- story_cloze
	- summscreen
	- sun397
	- super_glue
	- svhn_cropped
	- symmetric_solids
	- tao
	- tatoeba
	- ted_hrlr_translate
	- ted_multi_translate
	- tedlium
	- tf_flowers
	- the300w_lp
	- tiny_shakespeare
	- titanic
	- trec
	- trivia_qa
	- tydi_qa
	- uc_merced
	- ucf101
	- unified_qa
	- universal_dependencies
	- unnatural_instructions
	- user_libri_audio
	- user_libri_text
	- vctk
	- visual_domain_decathlon
	- voc
	- voxceleb
	- voxforge
	- waymo_open_dataset
	- web_graph
	- web_nlg
	- web_questions
	- webvid
	- wider_face
	- wiki40b
	- wiki_auto
	- wiki_bio
	- wiki_dialog
	- wiki_table_questions
	- wiki_table_text
	- wikiann
	- wikihow
	- wikipedia
	- wikipedia_toxicity_subtypes
	- wine_quality
	- winogrande
	- wit
	- wit_kaggle
	- wmt13_translate
	- wmt14_translate
	- wmt15_translate
	- wmt16_translate
	- wmt17_translate
	- wmt18_translate
	- wmt19_translate
	- wmt_t2t_translate
	- wmt_translate
	- wordnet
	- wsc273
	- xnli
	- xquad
	- xsum
	- xtreme_pawsx
	- xtreme_pos
	- xtreme_s
	- xtreme_xnli
	- yahoo_ltrc
	- yelp_polarity_reviews
	- yes_no
	- youtube_vis

Check that:
    - if dataset was added recently, it may only be available
      in `tfds-nightly`
    - the dataset name is spelled correctly
    - dataset class defines all base class abstract methods
    - the module defining the dataset class is imported

The builder directory /congcong/tensorflow_datasets/aloha_game doesn't contain any versions.
No builder could be found in the directory: /congcong/tensorflow_datasets for the builder: aloha_game.
No registered data_dirs were found in:
	- /congcong/tensorflow_datasets
Dataset aloha_game not found.
Available datasets:
	- abstract_reasoning
	- accentdb
	- aeslc
	- aflw2k3d
	- ag_news_subset
	- ai2_arc
	- ai2_arc_with_ir
	- amazon_us_reviews
	- anli
	- answer_equivalence
	- arc
	- asqa
	- asset
	- assin2
	- bair_robot_pushing_small
	- bccd
	- beans
	- bee_dataset
	- beir
	- big_patent
	- bigearthnet
	- billsum
	- binarized_mnist
	- binary_alpha_digits
	- ble_wind_field
	- blimp
	- booksum
	- bool_q
	- bot_adversarial_dialogue
	- bucc
	- c4
	- c4_wsrs
	- caltech101
	- caltech_birds2010
	- caltech_birds2011
	- cardiotox
	- cars196
	- cassava
	- cats_vs_dogs
	- celeb_a
	- celeb_a_hq
	- cfq
	- cherry_blossoms
	- chexpert
	- cifar10
	- cifar100
	- cifar100_n
	- cifar10_1
	- cifar10_corrupted
	- cifar10_h
	- cifar10_n
	- citrus_leaves
	- cityscapes
	- civil_comments
	- clevr
	- clic
	- clinc_oos
	- cmaterdb
	- cnn_dailymail
	- coco
	- coco_captions
	- coil100
	- colorectal_histology
	- colorectal_histology_large
	- common_voice
	- conll2002
	- conll2003
	- controlled_noisy_web_labels
	- coqa
	- corr2cause
	- cos_e
	- cosmos_qa
	- covid19
	- covid19sum
	- crema_d
	- criteo
	- cs_restaurants
	- curated_breast_imaging_ddsm
	- cycle_gan
	- d4rl_adroit_door
	- d4rl_adroit_hammer
	- d4rl_adroit_pen
	- d4rl_adroit_relocate
	- d4rl_antmaze
	- d4rl_mujoco_ant
	- d4rl_mujoco_halfcheetah
	- d4rl_mujoco_hopper
	- d4rl_mujoco_walker2d
	- dart
	- databricks_dolly
	- davis
	- deep1b
	- deep_weeds
	- definite_pronoun_resolution
	- dementiabank
	- diabetic_retinopathy_detection
	- diamonds
	- div2k
	- dmlab
	- doc_nli
	- dolphin_number_word
	- domainnet
	- downsampled_imagenet
	- drop
	- dsprites
	- dtd
	- duke_ultrasound
	- e2e_cleaned
	- efron_morris75
	- emnist
	- eraser_multi_rc
	- esnli
	- eurosat
	- fashion_mnist
	- flic
	- flores
	- food101
	- forest_fires
	- fuss
	- gap
	- geirhos_conflict_stimuli
	- gem
	- genomics_ood
	- german_credit_numeric
	- gigaword
	- glove100_angular
	- glue
	- goemotions
	- gov_report
	- gpt3
	- gref
	- groove
	- grounded_scan
	- gsm8k
	- gtzan
	- gtzan_music_speech
	- hellaswag
	- higgs
	- hillstrom
	- horses_or_humans
	- howell
	- i_naturalist2017
	- i_naturalist2018
	- i_naturalist2021
	- imagenet2012
	- imagenet2012_corrupted
	- imagenet2012_fewshot
	- imagenet2012_multilabel
	- imagenet2012_real
	- imagenet2012_subset
	- imagenet_a
	- imagenet_lt
	- imagenet_pi
	- imagenet_r
	- imagenet_resized
	- imagenet_sketch
	- imagenet_v2
	- imagenette
	- imagewang
	- imdb_reviews
	- irc_disentanglement
	- iris
	- istella
	- kddcup99
	- kitti
	- kmnist
	- laion400m
	- lambada
	- lfw
	- librispeech
	- librispeech_lm
	- libritts
	- ljspeech
	- lm1b
	- locomotion
	- lost_and_found
	- lsun
	- lvis
	- malaria
	- math_dataset
	- math_qa
	- mctaco
	- media_sum
	- mlqa
	- mnist
	- mnist_corrupted
	- movie_lens
	- movie_rationales
	- movielens
	- moving_mnist
	- mrqa
	- mslr_web
	- mt_opt
	- mtnt
	- multi_news
	- multi_nli
	- multi_nli_mismatch
	- natural_instructions
	- natural_questions
	- natural_questions_open
	- newsroom
	- nsynth
	- nyu_depth_v2
	- ogbg_molpcba
	- omniglot
	- open_images_challenge2019_detection
	- open_images_v4
	- openbookqa
	- opinion_abstracts
	- opinosis
	- opus
	- oxford_flowers102
	- oxford_iiit_pet
	- para_crawl
	- pass
	- patch_camelyon
	- paws_wiki
	- paws_x_wiki
	- penguins
	- pet_finder
	- pg19
	- piqa
	- places365_small
	- placesfull
	- plant_leaves
	- plant_village
	- plantae_k
	- protein_net
	- q_re_cc
	- qa4mre
	- qasc
	- quac
	- quality
	- quickdraw_bitmap
	- race
	- radon
	- real_toxicity_prompts
	- reddit
	- reddit_disentanglement
	- reddit_tifu
	- ref_coco
	- resisc45
	- rlu_atari
	- rlu_atari_checkpoints
	- rlu_atari_checkpoints_ordered
	- rlu_control_suite
	- rlu_dmlab_explore_object_rewards_few
	- rlu_dmlab_explore_object_rewards_many
	- rlu_dmlab_rooms_select_nonmatching_object
	- rlu_dmlab_rooms_watermaze
	- rlu_dmlab_seekavoid_arena01
	- rlu_locomotion
	- rlu_rwrl
	- robomimic_mg
	- robomimic_mh
	- robomimic_ph
	- robonet
	- robosuite_panda_pick_place_can
	- rock_paper_scissors
	- rock_you
	- s3o4d
	- salient_span_wikipedia
	- samsum
	- savee
	- scan
	- scene_parse150
	- schema_guided_dialogue
	- sci_tail
	- scicite
	- scientific_papers
	- scrolls
	- segment_anything
	- sentiment140
	- shapes3d
	- sift1m
	- simpte
	- siscore
	- smallnorb
	- smartwatch_gestures
	- snli
	- so2sat
	- speech_commands
	- spoken_digit
	- squad
	- squad_question_generation
	- stanford_dogs
	- stanford_online_products
	- star_cfq
	- starcraft_video
	- stl10
	- story_cloze
	- summscreen
	- sun397
	- super_glue
	- svhn_cropped
	- symmetric_solids
	- tao
	- tatoeba
	- ted_hrlr_translate
	- ted_multi_translate
	- tedlium
	- tf_flowers
	- the300w_lp
	- tiny_shakespeare
	- titanic
	- trec
	- trivia_qa
	- tydi_qa
	- uc_merced
	- ucf101
	- unified_qa
	- universal_dependencies
	- unnatural_instructions
	- user_libri_audio
	- user_libri_text
	- vctk
	- visual_domain_decathlon
	- voc
	- voxceleb
	- voxforge
	- waymo_open_dataset
	- web_graph
	- web_nlg
	- web_questions
	- webvid
	- wider_face
	- wiki40b
	- wiki_auto
	- wiki_bio
	- wiki_dialog
	- wiki_table_questions
	- wiki_table_text
	- wikiann
	- wikihow
	- wikipedia
	- wikipedia_toxicity_subtypes
	- wine_quality
	- winogrande
	- wit
	- wit_kaggle
	- wmt13_translate
	- wmt14_translate
	- wmt15_translate
	- wmt16_translate
	- wmt17_translate
	- wmt18_translate
	- wmt19_translate
	- wmt_t2t_translate
	- wmt_translate
	- wordnet
	- wsc273
	- xnli
	- xquad
	- xsum
	- xtreme_pawsx
	- xtreme_pos
	- xtreme_s
	- xtreme_xnli
	- yahoo_ltrc
	- yelp_polarity_reviews
	- yes_no
	- youtube_vis

Check that:
    - if dataset was added recently, it may only be available
      in `tfds-nightly`
    - the dataset name is spelled correctly
    - dataset class defines all base class abstract methods
    - the module defining the dataset class is imported

The builder directory /congcong/tensorflow_datasets/aloha_game doesn't contain any versions.
No builder could be found in the directory: /congcong/tensorflow_datasets for the builder: aloha_game.
No registered data_dirs were found in:
	- /congcong/tensorflow_datasets
Dataset aloha_game not found.
Available datasets:
	- abstract_reasoning
	- accentdb
	- aeslc
	- aflw2k3d
	- ag_news_subset
	- ai2_arc
	- ai2_arc_with_ir
	- amazon_us_reviews
	- anli
	- answer_equivalence
	- arc
	- asqa
	- asset
	- assin2
	- bair_robot_pushing_small
	- bccd
	- beans
	- bee_dataset
	- beir
	- big_patent
	- bigearthnet
	- billsum
	- binarized_mnist
	- binary_alpha_digits
	- ble_wind_field
	- blimp
	- booksum
	- bool_q
	- bot_adversarial_dialogue
	- bucc
	- c4
	- c4_wsrs
	- caltech101
	- caltech_birds2010
	- caltech_birds2011
	- cardiotox
	- cars196
	- cassava
	- cats_vs_dogs
	- celeb_a
	- celeb_a_hq
	- cfq
	- cherry_blossoms
	- chexpert
	- cifar10
	- cifar100
	- cifar100_n
	- cifar10_1
	- cifar10_corrupted
	- cifar10_h
	- cifar10_n
	- citrus_leaves
	- cityscapes
	- civil_comments
	- clevr
	- clic
	- clinc_oos
	- cmaterdb
	- cnn_dailymail
	- coco
	- coco_captions
	- coil100
	- colorectal_histology
	- colorectal_histology_large
	- common_voice
	- conll2002
	- conll2003
	- controlled_noisy_web_labels
	- coqa
	- corr2cause
	- cos_e
	- cosmos_qa
	- covid19
	- covid19sum
	- crema_d
	- criteo
	- cs_restaurants
	- curated_breast_imaging_ddsm
	- cycle_gan
	- d4rl_adroit_door
	- d4rl_adroit_hammer
	- d4rl_adroit_pen
	- d4rl_adroit_relocate
	- d4rl_antmaze
	- d4rl_mujoco_ant
	- d4rl_mujoco_halfcheetah
	- d4rl_mujoco_hopper
	- d4rl_mujoco_walker2d
	- dart
	- databricks_dolly
	- davis
	- deep1b
	- deep_weeds
	- definite_pronoun_resolution
	- dementiabank
	- diabetic_retinopathy_detection
	- diamonds
	- div2k
	- dmlab
	- doc_nli
	- dolphin_number_word
	- domainnet
	- downsampled_imagenet
	- drop
	- dsprites
	- dtd
	- duke_ultrasound
	- e2e_cleaned
	- efron_morris75
	- emnist
	- eraser_multi_rc
	- esnli
	- eurosat
	- fashion_mnist
	- flic
	- flores
	- food101
	- forest_fires
	- fuss
	- gap
	- geirhos_conflict_stimuli
	- gem
	- genomics_ood
	- german_credit_numeric
	- gigaword
	- glove100_angular
	- glue
	- goemotions
	- gov_report
	- gpt3
	- gref
	- groove
	- grounded_scan
	- gsm8k
	- gtzan
	- gtzan_music_speech
	- hellaswag
	- higgs
	- hillstrom
	- horses_or_humans
	- howell
	- i_naturalist2017
	- i_naturalist2018
	- i_naturalist2021
	- imagenet2012
	- imagenet2012_corrupted
	- imagenet2012_fewshot
	- imagenet2012_multilabel
	- imagenet2012_real
	- imagenet2012_subset
	- imagenet_a
	- imagenet_lt
	- imagenet_pi
	- imagenet_r
	- imagenet_resized
	- imagenet_sketch
	- imagenet_v2
	- imagenette
	- imagewang
	- imdb_reviews
	- irc_disentanglement
	- iris
	- istella
	- kddcup99
	- kitti
	- kmnist
	- laion400m
	- lambada
	- lfw
	- librispeech
	- librispeech_lm
	- libritts
	- ljspeech
	- lm1b
	- locomotion
	- lost_and_found
	- lsun
	- lvis
	- malaria
	- math_dataset
	- math_qa
	- mctaco
	- media_sum
	- mlqa
	- mnist
	- mnist_corrupted
	- movie_lens
	- movie_rationales
	- movielens
	- moving_mnist
	- mrqa
	- mslr_web
	- mt_opt
	- mtnt
	- multi_news
	- multi_nli
	- multi_nli_mismatch
	- natural_instructions
	- natural_questions
	- natural_questions_open
	- newsroom
	- nsynth
	- nyu_depth_v2
	- ogbg_molpcba
	- omniglot
	- open_images_challenge2019_detection
	- open_images_v4
	- openbookqa
	- opinion_abstracts
	- opinosis
	- opus
	- oxford_flowers102
	- oxford_iiit_pet
	- para_crawl
	- pass
	- patch_camelyon
	- paws_wiki
	- paws_x_wiki
	- penguins
	- pet_finder
	- pg19
	- piqa
	- places365_small
	- placesfull
	- plant_leaves
	- plant_village
	- plantae_k
	- protein_net
	- q_re_cc
	- qa4mre
	- qasc
	- quac
	- quality
	- quickdraw_bitmap
	- race
	- radon
	- real_toxicity_prompts
	- reddit
	- reddit_disentanglement
	- reddit_tifu
	- ref_coco
	- resisc45
	- rlu_atari
	- rlu_atari_checkpoints
	- rlu_atari_checkpoints_ordered
	- rlu_control_suite
	- rlu_dmlab_explore_object_rewards_few
	- rlu_dmlab_explore_object_rewards_many
	- rlu_dmlab_rooms_select_nonmatching_object
	- rlu_dmlab_rooms_watermaze
	- rlu_dmlab_seekavoid_arena01
	- rlu_locomotion
	- rlu_rwrl
	- robomimic_mg
	- robomimic_mh
	- robomimic_ph
	- robonet
	- robosuite_panda_pick_place_can
	- rock_paper_scissors
	- rock_you
	- s3o4d
	- salient_span_wikipedia
	- samsum
	- savee
	- scan
	- scene_parse150
	- schema_guided_dialogue
	- sci_tail
	- scicite
	- scientific_papers
	- scrolls
	- segment_anything
	- sentiment140
	- shapes3d
	- sift1m
	- simpte
	- siscore
	- smallnorb
	- smartwatch_gestures
	- snli
	- so2sat
	- speech_commands
	- spoken_digit
	- squad
	- squad_question_generation
	- stanford_dogs
	- stanford_online_products
	- star_cfq
	- starcraft_video
	- stl10
	- story_cloze
	- summscreen
	- sun397
	- super_glue
	- svhn_cropped
	- symmetric_solids
	- tao
	- tatoeba
	- ted_hrlr_translate
	- ted_multi_translate
	- tedlium
	- tf_flowers
	- the300w_lp
	- tiny_shakespeare
	- titanic
	- trec
	- trivia_qa
	- tydi_qa
	- uc_merced
	- ucf101
	- unified_qa
	- universal_dependencies
	- unnatural_instructions
	- user_libri_audio
	- user_libri_text
	- vctk
	- visual_domain_decathlon
	- voc
	- voxceleb
	- voxforge
	- waymo_open_dataset
	- web_graph
	- web_nlg
	- web_questions
	- webvid
	- wider_face
	- wiki40b
	- wiki_auto
	- wiki_bio
	- wiki_dialog
	- wiki_table_questions
	- wiki_table_text
	- wikiann
	- wikihow
	- wikipedia
	- wikipedia_toxicity_subtypes
	- wine_quality
	- winogrande
	- wit
	- wit_kaggle
	- wmt13_translate
	- wmt14_translate
	- wmt15_translate
	- wmt16_translate
	- wmt17_translate
	- wmt18_translate
	- wmt19_translate
	- wmt_t2t_translate
	- wmt_translate
	- wordnet
	- wsc273
	- xnli
	- xquad
	- xsum
	- xtreme_pawsx
	- xtreme_pos
	- xtreme_s
	- xtreme_xnli
	- yahoo_ltrc
	- yelp_polarity_reviews
	- yes_no
	- youtube_vis

Check that:
    - if dataset was added recently, it may only be available
      in `tfds-nightly`
    - the dataset name is spelled correctly
    - dataset class defines all base class abstract methods
    - the module defining the dataset class is imported

The builder directory /congcong/tensorflow_datasets/aloha_game doesn't contain any versions.
No builder could be found in the directory: /congcong/tensorflow_datasets for the builder: aloha_game.
No registered data_dirs were found in:
	- /congcong/tensorflow_datasets

Traceback (most recent call last):


  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
    finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune
    train_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
    _, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 202, in make_dataset_from_rlds
    builder = tfds.builder(name, data_dir=data_dir)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py", line 166, in __call__
    return function(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 215, in builder
    raise not_found_error
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 196, in builder
    cls = builder_cls(str(name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/load.py", line 121, in builder_cls
    cls = registered.imported_builder_cls(str(ds_name))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/registered.py", line 301, in imported_builder_cls
    raise DatasetNotFoundError(f'Dataset {name} not found.')
tensorflow_datasets.core.registered.DatasetNotFoundError: Dataset aloha_game not found.
Available datasets:
	- abstract_reasoning
	- accentdb
	- aeslc
	- aflw2k3d
	- ag_news_subset
	- ai2_arc
	- ai2_arc_with_ir
	- amazon_us_reviews
	- anli
	- answer_equivalence
	- arc
	- asqa
	- asset
	- assin2
	- bair_robot_pushing_small
	- bccd
	- beans
	- bee_dataset
	- beir
	- big_patent
	- bigearthnet
	- billsum
	- binarized_mnist
	- binary_alpha_digits
	- ble_wind_field
	- blimp
	- booksum
	- bool_q
	- bot_adversarial_dialogue
	- bucc
	- c4
	- c4_wsrs
	- caltech101
	- caltech_birds2010
	- caltech_birds2011
	- cardiotox
	- cars196
	- cassava
	- cats_vs_dogs
	- celeb_a
	- celeb_a_hq
	- cfq
	- cherry_blossoms
	- chexpert
	- cifar10
	- cifar100
	- cifar100_n
	- cifar10_1
	- cifar10_corrupted
	- cifar10_h
	- cifar10_n
	- citrus_leaves
	- cityscapes
	- civil_comments
	- clevr
	- clic
	- clinc_oos
	- cmaterdb
	- cnn_dailymail
	- coco
	- coco_captions
	- coil100
	- colorectal_histology
	- colorectal_histology_large
	- common_voice
	- conll2002
	- conll2003
	- controlled_noisy_web_labels
	- coqa
	- corr2cause
	- cos_e
	- cosmos_qa
	- covid19
	- covid19sum
	- crema_d
	- criteo
	- cs_restaurants
	- curated_breast_imaging_ddsm
	- cycle_gan
	- d4rl_adroit_door
	- d4rl_adroit_hammer
	- d4rl_adroit_pen
	- d4rl_adroit_relocate
	- d4rl_antmaze
	- d4rl_mujoco_ant
	- d4rl_mujoco_halfcheetah
	- d4rl_mujoco_hopper
	- d4rl_mujoco_walker2d
	- dart
	- databricks_dolly
	- davis
	- deep1b
	- deep_weeds
	- definite_pronoun_resolution
	- dementiabank
	- diabetic_retinopathy_detection
	- diamonds
	- div2k
	- dmlab
	- doc_nli
	- dolphin_number_word
	- domainnet
	- downsampled_imagenet
	- drop
	- dsprites
	- dtd
	- duke_ultrasound
	- e2e_cleaned
	- efron_morris75
	- emnist
	- eraser_multi_rc
	- esnli
	- eurosat
	- fashion_mnist
	- flic
	- flores
	- food101
	- forest_fires
	- fuss
	- gap
	- geirhos_conflict_stimuli
	- gem
	- genomics_ood
	- german_credit_numeric
	- gigaword
	- glove100_angular
	- glue
	- goemotions
	- gov_report
	- gpt3
	- gref
	- groove
	- grounded_scan
	- gsm8k
	- gtzan
	- gtzan_music_speech
	- hellaswag
	- higgs
	- hillstrom
	- horses_or_humans
	- howell
	- i_naturalist2017
	- i_naturalist2018
	- i_naturalist2021
	- imagenet2012
	- imagenet2012_corrupted
	- imagenet2012_fewshot
	- imagenet2012_multilabel
	- imagenet2012_real
	- imagenet2012_subset
	- imagenet_a
	- imagenet_lt
	- imagenet_pi
	- imagenet_r
	- imagenet_resized
	- imagenet_sketch
	- imagenet_v2
	- imagenette
	- imagewang
	- imdb_reviews
	- irc_disentanglement
	- iris
	- istella
	- kddcup99
	- kitti
	- kmnist
	- laion400m
	- lambada
	- lfw
	- librispeech
	- librispeech_lm
	- libritts
	- ljspeech
	- lm1b
	- locomotion
	- lost_and_found
	- lsun
	- lvis
	- malaria
	- math_dataset
	- math_qa
	- mctaco
	- media_sum
	- mlqa
	- mnist
	- mnist_corrupted
	- movie_lens
	- movie_rationales
	- movielens
	- moving_mnist
	- mrqa
	- mslr_web
	- mt_opt
	- mtnt
	- multi_news
	- multi_nli
	- multi_nli_mismatch
	- natural_instructions
	- natural_questions
	- natural_questions_open
	- newsroom
	- nsynth
	- nyu_depth_v2
	- ogbg_molpcba
	- omniglot
	- open_images_challenge2019_detection
	- open_images_v4
	- openbookqa
	- opinion_abstracts
	- opinosis
	- opus
	- oxford_flowers102
	- oxford_iiit_pet
	- para_crawl
	- pass
	- patch_camelyon
	- paws_wiki
	- paws_x_wiki
	- penguins
	- pet_finder
	- pg19
	- piqa
	- places365_small
	- placesfull
	- plant_leaves
	- plant_village
	- plantae_k
	- protein_net
	- q_re_cc
	- qa4mre
	- qasc
	- quac
	- quality
	- quickdraw_bitmap
	- race
	- radon
	- real_toxicity_prompts
	- reddit
	- reddit_disentanglement
	- reddit_tifu
	- ref_coco
	- resisc45
	- rlu_atari
	- rlu_atari_checkpoints
	- rlu_atari_checkpoints_ordered
	- rlu_control_suite
	- rlu_dmlab_explore_object_rewards_few
	- rlu_dmlab_explore_object_rewards_many
	- rlu_dmlab_rooms_select_nonmatching_object
	- rlu_dmlab_rooms_watermaze
	- rlu_dmlab_seekavoid_arena01
	- rlu_locomotion
	- rlu_rwrl
	- robomimic_mg
	- robomimic_mh
	- robomimic_ph
	- robonet
	- robosuite_panda_pick_place_can
	- rock_paper_scissors
	- rock_you
	- s3o4d
	- salient_span_wikipedia
	- samsum
	- savee
	- scan
	- scene_parse150
	- schema_guided_dialogue
	- sci_tail
	- scicite
	- scientific_papers
	- scrolls
	- segment_anything
	- sentiment140
	- shapes3d
	- sift1m
	- simpte
	- siscore
	- smallnorb
	- smartwatch_gestures
	- snli
	- so2sat
	- speech_commands
	- spoken_digit
	- squad
	- squad_question_generation
	- stanford_dogs
	- stanford_online_products
	- star_cfq
	- starcraft_video
	- stl10
	- story_cloze
	- summscreen
	- sun397
	- super_glue
	- svhn_cropped
	- symmetric_solids
	- tao
	- tatoeba
	- ted_hrlr_translate
	- ted_multi_translate
	- tedlium
	- tf_flowers
	- the300w_lp
	- tiny_shakespeare
	- titanic
	- trec
	- trivia_qa
	- tydi_qa
	- uc_merced
	- ucf101
	- unified_qa
	- universal_dependencies
	- unnatural_instructions
	- user_libri_audio
	- user_libri_text
	- vctk
	- visual_domain_decathlon
	- voc
	- voxceleb
	- voxforge
	- waymo_open_dataset
	- web_graph
	- web_nlg
	- web_questions
	- webvid
	- wider_face
	- wiki40b
	- wiki_auto
	- wiki_bio
	- wiki_dialog
	- wiki_table_questions
	- wiki_table_text
	- wikiann
	- wikihow
	- wikipedia
	- wikipedia_toxicity_subtypes
	- wine_quality
	- winogrande
	- wit
	- wit_kaggle
	- wmt13_translate
	- wmt14_translate
	- wmt15_translate
	- wmt16_translate
	- wmt17_translate
	- wmt18_translate
	- wmt19_translate
	- wmt_t2t_translate
	- wmt_translate
	- wordnet
	- wsc273
	- xnli
	- xquad
	- xsum
	- xtreme_pawsx
	- xtreme_pos
	- xtreme_s
	- xtreme_xnli
	- yahoo_ltrc
	- yelp_polarity_reviews
	- yes_no
	- youtube_vis

Check that:
    - if dataset was added recently, it may only be available
      in `tfds-nightly`
    - the dataset name is spelled correctly
    - dataset class defines all base class abstract methods
    - the module defining the dataset class is imported

The builder directory /congcong/tensorflow_datasets/aloha_game doesn't contain any versions.
No builder could be found in the directory: /congcong/tensorflow_datasets for the builder: aloha_game.
No registered data_dirs were found in:
	- /congcong/tensorflow_datasets

[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state[0m at: [34mhttps://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/emksfeg2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250821_013226-emksfeg2/logs[0m
[2025-08-21 01:34:58,515] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3994808) of binary: /home/congcong/miniconda3/envs/openvla-oft/bin/python3.10
Traceback (most recent call last):
  File "/home/congcong/miniconda3/envs/openvla-oft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
vla-scripts/finetune.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-08-21_01:34:58
  host      : dgx-18.cm.cluster
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3994809)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-08-21_01:34:58
  host      : dgx-18.cm.cluster
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3994810)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-08-21_01:34:58
  host      : dgx-18.cm.cluster
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3994811)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-21_01:34:58
  host      : dgx-18.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3994808)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Thu Aug 21 01:35:46 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:61:00.0 Off |                    0 |
| N/A   31C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 01:35:53.000206: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:35:53.031618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:35:53.031645: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:35:53.032682: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:35:53.037693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:35:54.148059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 01:35:58.923521: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_013610-4yckf4ft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/4yckf4ft
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 45343.83it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_013611
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  5.30it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  6.69it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.54it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.08it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
2025-08-21 01:36:19.585230: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
Traceback (most recent call last):
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
    finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune
    train_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
    _, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 211, in make_dataset_from_rlds
    ).traj_map(restructure, num_parallel_calls)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/dlimp/dataset.py", line 17, in wrapper
    result = f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/dlimp/dataset.py", line 178, in traj_map
    return super().map(fn, num_parallel_calls=num_parallel_calls, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 2280, in map
    return map_op._map_v2(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py", line 40, in _map_v2
    return _ParallelMapDataset(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py", line 148, in __init__
    self._map_func = structured_function.StructuredFunctionWrapper(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py", line 265, in __init__
    self._function = fn_factory()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 1227, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 1197, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 695, in _initialize
    self._concrete_variable_creation_fn = tracing_compilation.trace_function(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 178, in trace_function
    concrete_function = _maybe_define_function(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 283, in _maybe_define_function
    concrete_function = _create_concrete_function(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 310, in _create_concrete_function
    traced_func_graph = func_graph_module.func_graph_from_py_func(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py", line 1059, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 598, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py", line 231, in wrapped_fn
    ret = wrapper_helper(*args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py", line 161, in wrapper_helper
    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 693, in wrapper
    raise e.ag_error_metadata.to_exception(e)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 690, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 439, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/__autograph_generated_file_kz5h3vu.py", line 165, in tf__restructure
    ag__.if_stmt(ag__.ld(absolute_action_mask) is not None, if_body_8, else_body_8, get_state_10, set_state_10, ("traj['absolute_action_mask']",), 1)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 1217, in if_stmt
    _py_if_stmt(cond, body, orelse)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 1270, in _py_if_stmt
    return body() if cond else orelse()
  File "/tmp/__autograph_generated_file_kz5h3vu.py", line 160, in if_body_8
    ag__.if_stmt(ag__.converted_call(ag__.ld(len), (ag__.ld(absolute_action_mask),), None, fscope) != ag__.ld(traj)['action'].shape[-1], if_body_7, else_body_7, get_state_9, set_state_9, (), 0)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 1217, in if_stmt
    _py_if_stmt(cond, body, orelse)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 1270, in _py_if_stmt
    return body() if cond else orelse()
  File "/tmp/__autograph_generated_file_kz5h3vu.py", line 156, in if_body_7
    raise ag__.converted_call(ag__.ld(ValueError), (f"Length of absolute_action_mask ({ag__.converted_call(ag__.ld(len), (ag__.ld(absolute_action_mask),), None, fscope)}) does not match action dimension ({ag__.ld(traj)['action'].shape[-1]}).",), None, fscope)
ValueError: in user code:

    File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 191, in restructure  *
        raise ValueError(

    ValueError: Length of absolute_action_mask (14) does not match action dimension (7).

[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state[0m at: [34mhttps://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/4yckf4ft[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250821_013610-4yckf4ft/logs[0m
[2025-08-21 01:36:24,568] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1283508) of binary: /home/congcong/miniconda3/envs/openvla-oft/bin/python3.10
Traceback (most recent call last):
  File "/home/congcong/miniconda3/envs/openvla-oft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
vla-scripts/finetune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-21_01:36:24
  host      : dgx-15.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1283508)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Thu Aug 21 01:45:54 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:9D:00.0 Off |                    0 |
| N/A   26C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 01:46:00.916157: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:46:00.949592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:46:00.949623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:46:00.950917: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:46:00.956734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:46:02.069916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 01:46:06.998389: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_014617-wrvyfh8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/wrvyfh8q
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 24260.11it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_014619
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  5.24it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  6.67it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.52it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.05it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
08/21 [01:46:27] WARNING  | >> [*] Skipping `aloha_game` due  materialize.py:135
                          to Error: Cannot load `aloha_game`;                   
                          only EEF_POS & EEF_R6 &                               
                          JOINT_POS_BIMANUAL actions                            
                          supported!                                            

######################################################################################
# Loading the following 0 datasets (incl. sampling weight):                         #
######################################################################################

Traceback (most recent call last):
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
    finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 978, in finetune
    train_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 522, in make_interleaved_dataset
    dataset_len = int((np.array(dataset_sizes) / sample_weights)[primary_dataset_indices].max())
IndexError: arrays used as indices must be of integer (or boolean) type
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state[0m at: [34mhttps://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/wrvyfh8q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250821_014617-wrvyfh8q/logs[0m
[2025-08-21 01:46:32,738] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1297783) of binary: /home/congcong/miniconda3/envs/openvla-oft/bin/python3.10
Traceback (most recent call last):
  File "/home/congcong/miniconda3/envs/openvla-oft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
vla-scripts/finetune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-21_01:46:32
  host      : dgx-15.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1297783)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Thu Aug 21 01:53:03 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:1B:00.0 Off |                    0 |
| N/A   36C    P0             114W / 700W |      4MiB / 81559MiB |      5%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 01:53:09.387864: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:53:09.420658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:53:09.420686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:53:09.421784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:53:09.426982: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:53:10.515503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 01:53:15.339391: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_015325-nlbwk7zh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/nlbwk7zh
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 17395.73it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_015327
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  5.00it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  6.42it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.31it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  6.83it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
2025-08-21 01:53:34.383332: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [01:53:34] INFO     | >> [*] Computing dataset           data_utils.py:223
                          statistics. This may take a bit, but                  
                          should only need to happen once.                      
  0%|          | 0/100 [00:00<?, ?it/s] 45%|████▌     | 45/100 [00:00<00:00, 375.54it/s]100%|██████████| 100/100 [00:00<00:00, 555.32it/s]
2025-08-21 01:53:35.058288: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization

######################################################################################
# Loading the following 1 datasets (incl. sampling weight):                         #
# aloha_game: ==============================================================1.000000 #
######################################################################################

08/21 [01:53:35] INFO     | >> [*] Threads per Dataset: [1]       dataset.py:528
                 INFO     | >> [*] Reads per Dataset: [1]         dataset.py:529
                 INFO     | >> [*] Constructing datasets...       dataset.py:532
2025-08-21 01:53:35.378063: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
                 INFO     | >> [*] Applying frame transforms on   dataset.py:572
                          dataset...                                            
2025-08-21 01:53:36.813466: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [01:53:36] INFO     | >> [*] Loading existing dataset    data_utils.py:199
                          statistics from                                       
                          /home/congcong/tensorflow_datasets/a                  
                          loha_game/1.0.0/dataset_statistics_4                  
                          c080c1a059961db0412d95118a1e8218a9d3                  
                          34b0c40f2f5feb80b9cb0fa3c0c.json.                     
Traceback (most recent call last):
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 1142, in <module>
    finetune()
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/draccus/argparsing.py", line 203, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/home/congcong/yanzhengyang/openvla-oft/vla-scripts/finetune.py", line 987, in finetune
    val_dataset = RLDSDataset(
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 169, in __init__
    self.dataset, self.dataset_length, self.dataset_statistics = self.make_dataset(rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/datasets.py", line 172, in make_dataset
    return make_interleaved_dataset(**rlds_config)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 507, in make_interleaved_dataset
    _, dataset_statistics = make_dataset_from_rlds(**data_kwargs, train=train)
  File "/home/congcong/yanzhengyang/openvla-oft/prismatic/vla/datasets/rlds/dataset.py", line 236, in make_dataset_from_rlds
    dataset = dl.DLataset.from_rlds(builder, split=split, shuffle=shuffle, num_parallel_reads=num_parallel_reads)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/dlimp/dataset.py", line 144, in from_rlds
    dataset = _wrap(builder.as_dataset, False)(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/dlimp/dataset.py", line 17, in wrapper
    result = f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py", line 166, in __call__
    return function(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py", line 886, in as_dataset
    all_ds = tree_utils.map_structure(build_single_dataset, split)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tree/__init__.py", line 428, in map_structure
    [func(*args) for args in zip(*map(flatten, structures))])
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tree/__init__.py", line 428, in <listcomp>
    [func(*args) for args in zip(*map(flatten, structures))])
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py", line 904, in _build_single_dataset
    ds = self._as_dataset(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py", line 1351, in _as_dataset
    return reader.read(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/reader.py", line 422, in read
    return tree_utils.map_structure(_read_instruction_to_ds, instructions)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tree/__init__.py", line 428, in map_structure
    [func(*args) for args in zip(*map(flatten, structures))])
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tree/__init__.py", line 428, in <listcomp>
    [func(*args) for args in zip(*map(flatten, structures))])
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/reader.py", line 413, in _read_instruction_to_ds
    file_instructions = splits_dict[instruction].file_instructions
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/splits.py", line 411, in __getitem__
    instructions = _make_file_instructions(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/splits.py", line 512, in _make_file_instructions
    absolute_instructions = _make_absolute_instructions(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/splits.py", line 470, in _make_absolute_instructions
    return instruction.to_absolute(split_info_map)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/splits.py", line 684, in to_absolute
    return [_rel_to_abs_instr(self, split_infos)]
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/tensorflow_datasets/core/splits.py", line 780, in _rel_to_abs_instr
    raise ValueError(
ValueError: Unknown split 'val'. Should be one of ['train'].
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state[0m at: [34mhttps://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/nlbwk7zh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250821_015325-nlbwk7zh/logs[0m
[2025-08-21 01:53:41,324] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1308968) of binary: /home/congcong/miniconda3/envs/openvla-oft/bin/python3.10
Traceback (most recent call last):
  File "/home/congcong/miniconda3/envs/openvla-oft/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/congcong/miniconda3/envs/openvla-oft/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
vla-scripts/finetune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-08-21_01:53:41
  host      : dgx-15.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1308968)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Thu Aug 21 01:56:28 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:1B:00.0 Off |                    0 |
| N/A   20C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 01:56:34.632621: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:56:34.666706: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:56:34.666733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:56:34.667961: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:56:34.673628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:56:35.772853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 01:56:40.573551: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_015650-renzt2d9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/renzt2d9
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 14882.21it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_015652
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  5.32it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  6.72it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.52it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.08it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
2025-08-21 01:56:59.006948: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [01:56:59] INFO     | >> [*] Loading existing dataset    data_utils.py:199
                          statistics from                                       
                          /home/congcong/tensorflow_datasets/a                  
                          loha_game/1.0.0/dataset_statistics_4                  
                          c080c1a059961db0412d95118a1e8218a9d3                  
                          34b0c40f2f5feb80b9cb0fa3c0c.json.                     
2025-08-21 01:56:59.281669: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization

######################################################################################
# Loading the following 1 datasets (incl. sampling weight):                         #
# aloha_game: ==============================================================1.000000 #
######################################################################################

                 INFO     | >> [*] Threads per Dataset: [1]       dataset.py:528
                 INFO     | >> [*] Reads per Dataset: [1]         dataset.py:529
                 INFO     | >> [*] Constructing datasets...       dataset.py:532
2025-08-21 01:56:59.584700: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [01:57:00] INFO     | >> [*] Applying frame transforms on   dataset.py:572
                          dataset...                                            
08/21 [01:57:01] INFO     | >> [*] Saved dataset statistics    data_utils.py:284
                          file at path                                          
                          /home/congcong/yanzhengyang/openvla-                  
                          7b+aloha_game+b1+lr-0.0005+lora-r32+                  
                          dropout-0.0--image_aug--parallel_dec                  
                          --25_acts_chunk--continuous_acts--L1                  
                          _regression--3rd_person_img--left_ri                  
                          ght_wrist_imgs--proprio_state/datase                  
                          t_statistics.json                                     
  0%|          | 0/100005 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755712621.377105 1314661 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755712621.377515 1314661 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755712621.377551 1314661 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755712621.377653 1314661 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755712621.377685 1314661 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755712621.377760 1314661 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
slurmstepd: error: *** JOB 266997 ON dgx-15 CANCELLED AT 2025-08-21T01:58:58 ***
Thu Aug 21 01:59:33 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:1B:00.0 Off |                    0 |
| N/A   23C    P0              70W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H800                    On  | 00000000:61:00.0 Off |                    0 |
| N/A   26C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H800                    On  | 00000000:C3:00.0 Off |                    0 |
| N/A   26C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H800                    On  | 00000000:DF:00.0 Off |                    0 |
| N/A   26C    P0              68W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
[2025-08-21 01:59:37,351] torch.distributed.run: [WARNING] 
[2025-08-21 01:59:37,351] torch.distributed.run: [WARNING] *****************************************
[2025-08-21 01:59:37,351] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2025-08-21 01:59:37,351] torch.distributed.run: [WARNING] *****************************************
2025-08-21 01:59:43.298194: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:59:43.298192: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:59:43.298203: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:59:43.298279: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 01:59:43.487014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:59:43.487012: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:59:43.487014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:59:43.487017: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 01:59:43.487055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:59:43.487058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:59:43.487064: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:59:43.487170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 01:59:43.516712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:59:43.516712: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:59:43.516709: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:59:43.516719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 01:59:43.581486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:59:43.581486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:59:43.581487: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:59:43.581522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 01:59:45.066903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-08-21 01:59:45.087886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-08-21 01:59:45.112064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-08-21 01:59:45.117943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:Using ALOHA constants:Using ALOHA constants:

  NUM_ACTIONS_CHUNK = 25  NUM_ACTIONS_CHUNK = 25


  ACTION_DIM = 7  NUM_ACTIONS_CHUNK = 25  ACTION_DIM = 7


  PROPRIO_DIM = 7  ACTION_DIM = 7  PROPRIO_DIM = 7


  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds

If needed, manually set the correct constants in `prismatic/vla/constants.py`!  ACTION_PROPRIO_NORMALIZATION_TYPE = boundsIf needed, manually set the correct constants in `prismatic/vla/constants.py`!


If needed, manually set the correct constants in `prismatic/vla/constants.py`!
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 01:59:52.233998: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.235017: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.236570: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.237541: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.238268: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.238798: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.238863: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.239847: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.241001: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.241967: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.242022: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.242488: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.245946: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.246401: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.250367: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2025-08-21 01:59:52.250827: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 5930.21it/s]
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 31248.95it/s]
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 72944.42it/s]
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_020002-aixer7ro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/aixer7ro
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 26829.24it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_020004
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.43it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.44it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.77it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.74it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  3.00it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.99it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.51it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.49it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.69it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.38it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  3.27it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.88it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.67it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.37it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  3.24it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# trainable params in action_head: 151117831
# trainable params in action_head: 151117831# trainable params in action_head: 151117831

# total trainable params: 261946119# total trainable params: 261946119
# total trainable params: 261946119

# total trainable params: 261946119
2025-08-21 02:01:07.122819: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.122959: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.122968: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.123788: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:01:07] INFO     | >> [*] Loading existing dataset    data_utils.py:199
                          statistics from                                       
                          /home/congcong/tensorflow_datasets/a                  
                          loha_game/1.0.0/dataset_statistics_4                  
                          c080c1a059961db0412d95118a1e8218a9d3                  
                          34b0c40f2f5feb80b9cb0fa3c0c.json.                     
2025-08-21 02:01:07.414971: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.415261: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.415293: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.417899: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization

######################################################################################
######################################################################################
######################################################################################

# Loading the following 1 datasets (incl. sampling weight):                         #

# Loading the following 1 datasets (incl. sampling weight):                         ## Loading the following 1 datasets (incl. sampling weight):                         #

# aloha_game: ==============================================================1.000000 #
######################################################################################

# aloha_game: ==============================================================1.000000 ## aloha_game: ==============================================================1.000000 #

######################################################################################
######################################################################################



######################################################################################
# Loading the following 1 datasets (incl. sampling weight):                         #
# aloha_game: ==============================================================1.000000 #
######################################################################################

                 INFO     | >> [*] Threads per Dataset: [1]       dataset.py:528
                 INFO     | >> [*] Reads per Dataset: [1]         dataset.py:529
                 INFO     | >> [*] Constructing datasets...       dataset.py:532
2025-08-21 02:01:07.736610: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.736867: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.737493: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
2025-08-21 02:01:07.741427: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:01:08] INFO     | >> [*] Applying frame transforms on   dataset.py:572
                          dataset...                                            
  0%|          | 0/100005 [00:00<?, ?it/s]  0%|          | 0/100005 [00:00<?, ?it/s]  0%|          | 0/100005 [00:00<?, ?it/s]08/21 [02:01:09] INFO     | >> [*] Saved dataset statistics    data_utils.py:284
                          file at path                                          
                          /home/congcong/yanzhengyang/openvla-                  
                          7b+aloha_game+b1+lr-0.0005+lora-r32+                  
                          dropout-0.0--image_aug--parallel_dec                  
                          --25_acts_chunk--continuous_acts--L1                  
                          _regression--3rd_person_img--left_ri                  
                          ght_wrist_imgs--proprio_state/datase                  
                          t_statistics.json                                     
  0%|          | 0/100005 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755712869.739954 1154753 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755712869.740400 1154753 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755712869.740443 1154753 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755712869.740558 1154753 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755712869.740598 1154753 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755712869.740683 1154753 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755712869.742476 1154752 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755712869.742934 1154752 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755712869.742983 1154752 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755712869.743152 1154752 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755712869.742874 1154751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755712869.743207 1154752 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755712869.743240 1154751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755712869.743279 1154751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755712869.743300 1154752 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
W0000 00:00:1755712869.743396 1154751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755712869.743432 1154751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755712869.743492 1154751 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755712869.830045 1154750 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755712869.830511 1154750 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755712869.830548 1154750 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755712869.830659 1154750 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755712869.830705 1154750 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755712869.830779 1154750 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 112 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
slurmstepd: error: *** JOB 266999 ON dgx-14 CANCELLED AT 2025-08-21T02:26:53 ***
Thu Aug 21 02:29:47 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:61:00.0 Off |                    0 |
| N/A   36C    P0              69W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 02:29:53.362360: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 02:29:53.396030: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 02:29:53.396057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 02:29:53.397318: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 02:29:53.402926: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 02:29:54.502027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 02:29:59.412831: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_023009-dy7q51bg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/dy7q51bg
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 9445.45it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_023011
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.62it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  4.30it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.47it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.98it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
2025-08-21 02:30:18.855182: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:30:19] INFO     | >> [*] Loading existing dataset    data_utils.py:199
                          statistics from                                       
                          /home/congcong/tensorflow_datasets/a                  
                          loha_game/1.0.0/dataset_statistics_4                  
                          c080c1a059961db0412d95118a1e8218a9d3                  
                          34b0c40f2f5feb80b9cb0fa3c0c.json.                     
2025-08-21 02:30:19.135216: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization

######################################################################################
# Loading the following 1 datasets (incl. sampling weight):                         #
# aloha_game: ==============================================================1.000000 #
######################################################################################

                 INFO     | >> [*] Threads per Dataset: [1]       dataset.py:528
                 INFO     | >> [*] Reads per Dataset: [1]         dataset.py:529
                 INFO     | >> [*] Constructing datasets...       dataset.py:532
2025-08-21 02:30:19.452312: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:30:20] INFO     | >> [*] Applying frame transforms on   dataset.py:572
                          dataset...                                            
                 INFO     | >> [*] Saved dataset statistics    data_utils.py:284
                          file at path                                          
                          /home/congcong/yanzhengyang/openvla-                  
                          7b+aloha_game+b1+lr-0.0005+lora-r32+                  
                          dropout-0.0--image_aug--parallel_dec                  
                          --25_acts_chunk--continuous_acts--L1                  
                          _regression--3rd_person_img--left_ri                  
                          ght_wrist_imgs--proprio_state/datase                  
                          t_statistics.json                                     
  0%|          | 0/100005 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755714621.271285 1364812 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755714621.271606 1364812 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755714621.271644 1364812 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755714621.271735 1364812 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755714621.271763 1364812 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755714621.271830 1364812 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
slurmstepd: error: *** JOB 267031 ON dgx-15 CANCELLED AT 2025-08-21T02:33:05 ***
Thu Aug 21 02:33:17 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:43:00.0 Off |                    0 |
| N/A   38C    P0              69W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 02:33:28.702322: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 02:33:28.870079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 02:33:28.870205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 02:33:28.896284: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 02:33:28.953324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 02:33:31.622002: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 02:33:43.076695: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Thu Aug 21 02:33:47 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:61:00.0 Off |                    0 |
| N/A   26C    P0              66W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
slurmstepd: error: *** JOB 267036 ON dgx-06 CANCELLED AT 2025-08-21T02:33:50 ***
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_023352-v4hi0r27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/v4hi0r27
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 2145.73it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_023354
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.80it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.46it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  3.45it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.97it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
2025-08-21 02:34:36.813885: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:34:37] INFO     | >> [*] Loading existing dataset    data_utils.py:199
                          statistics from                                       
                          /home/congcong/tensorflow_datasets/a                  
                          loha_game/1.0.0/dataset_statistics_4                  
                          c080c1a059961db0412d95118a1e8218a9d3                  
                          34b0c40f2f5feb80b9cb0fa3c0c.json.                     
2025-08-21 02:34:37.115914: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization

######################################################################################
# Loading the following 1 datasets (incl. sampling weight):                         #
# aloha_game: ==============================================================1.000000 #
######################################################################################

                 INFO     | >> [*] Threads per Dataset: [1]       dataset.py:528
                 INFO     | >> [*] Reads per Dataset: [1]         dataset.py:529
                 INFO     | >> [*] Constructing datasets...       dataset.py:532
2025-08-21 02:34:37.423909: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:34:38] INFO     | >> [*] Applying frame transforms on   dataset.py:572
                          dataset...                                            
                 INFO     | >> [*] Saved dataset statistics    data_utils.py:284
                          file at path                                          
                          /home/congcong/yanzhengyang/openvla-                  
                          7b+aloha_game+b1+lr-0.0005+lora-r32+                  
                          dropout-0.0--image_aug--parallel_dec                  
                          --25_acts_chunk--continuous_acts--L1                  
                          _regression--3rd_person_img--left_ri                  
                          ght_wrist_imgs--proprio_state/datase                  
                          t_statistics.json                                     
  0%|          | 0/100005 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755714879.134369 1910462 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755714879.134708 1910462 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755714879.134753 1910462 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755714879.134851 1910462 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755714879.134882 1910462 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755714879.134956 1910462 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
slurmstepd: error: *** JOB 267035 ON dgx-06 CANCELLED AT 2025-08-21T02:35:44 ***
Thu Aug 21 02:36:47 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:43:00.0 Off |                    0 |
| N/A   38C    P0              69W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
2025-08-21 02:36:52.761214: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-08-21 02:36:52.795529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-08-21 02:36:52.795556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-08-21 02:36:52.796819: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-08-21 02:36:52.802502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-21 02:36:53.858971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using ALOHA constants:
  NUM_ACTIONS_CHUNK = 25
  ACTION_DIM = 7
  PROPRIO_DIM = 7
  ACTION_PROPRIO_NORMALIZATION_TYPE = bounds
If needed, manually set the correct constants in `prismatic/vla/constants.py`!
2025-08-21 02:36:58.536442: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
Fine-tuning OpenVLA Model `openvla/openvla-7b` on `aloha_game`
wandb: Currently logged in as: heisen0928 (heisen0928-the-hong-kong-polytechnic-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/congcong/yanzhengyang/openvla-oft/wandb/run-20250821_023708-wisu94lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ft+openvla-7b+aloha_game+b1+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--25_acts_chunk--continuous_acts--L1_regression--3rd_person_img--left_right_wrist_imgs--proprio_state
wandb: ⭐️ View project at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game
wandb: 🚀 View run at https://wandb.ai/heisen0928-the-hong-kong-polytechnic-university/aloha_game/runs/wisu94lx
Detected constants:
	NUM_ACTIONS_CHUNK: 25
	ACTION_DIM: 7
	PROPRIO_DIM: 7
	ACTION_PROPRIO_NORMALIZATION_TYPE: bounds
Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 18747.82it/s]
Created backup of original config at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json.back.20250821_023710
Updated config.json at: /home/congcong/.cache/huggingface/hub/models--openvla--openvla-7b/snapshots/31f090d05236101ebfc381b61c674dd4746d4ce0/config.json
Changes made:
  - Set AutoConfig to "configuration_prismatic.OpenVLAConfig"
  - Set AutoModelForVision2Seq to "modeling_prismatic.OpenVLAForActionPrediction"
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  5.65it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  6.67it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  7.24it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  6.94it/s]
trainable params: 110,828,288 || all params: 7,652,065,472 || trainable%: 1.4483
# trainable params in action_head: 151117831
# total trainable params: 261946119
2025-08-21 02:37:17.711173: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
08/21 [02:37:17] INFO     | >> [*] Loading existing dataset    data_utils.py:199
                          statistics from                                       
                          /home/congcong/tensorflow_datasets/a                  
                          loha_game/1.0.0/dataset_statistics_4                  
                          c080c1a059961db0412d95118a1e8218a9d3                  
                          34b0c40f2f5feb80b9cb0fa3c0c.json.                     
2025-08-21 02:37:17.986313: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization

######################################################################################
# Loading the following 1 datasets (incl. sampling weight):                         #
# aloha_game: ==============================================================1.000000 #
######################################################################################

08/21 [02:37:18] INFO     | >> [*] Threads per Dataset: [1]       dataset.py:528
                 INFO     | >> [*] Reads per Dataset: [1]         dataset.py:529
                 INFO     | >> [*] Constructing datasets...       dataset.py:532
2025-08-21 02:37:18.288748: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization
                 INFO     | >> [*] Applying frame transforms on   dataset.py:572
                          dataset...                                            
08/21 [02:37:19] INFO     | >> [*] Saved dataset statistics    data_utils.py:284
                          file at path                                          
                          /home/congcong/yanzhengyang/openvla-                  
                          7b+aloha_game+b1+lr-0.0005+lora-r32+                  
                          dropout-0.0--image_aug--parallel_dec                  
                          --25_acts_chunk--continuous_acts--L1                  
                          _regression--3rd_person_img--left_ri                  
                          ght_wrist_imgs--proprio_state/datase                  
                          t_statistics.json                                     
  0%|          | 0/100005 [00:00<?, ?it/s]cfg.use_diffusion: False
vla.train()
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1755715039.993878 1917530 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -14 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -20 } dim { size: -21 } dim { size: -14 } } }
W0000 00:00:1755715039.994192 1917530 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -15 } } } inputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -3 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -3 } dim { size: -22 } dim { size: -23 } dim { size: -15 } } }
W0000 00:00:1755715039.994226 1917530 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -16 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -24 } dim { size: -25 } dim { size: -16 } } }
W0000 00:00:1755715039.994317 1917530 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -17 } } } inputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -8 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -8 } dim { size: -35 } dim { size: -36 } dim { size: -17 } } }
W0000 00:00:1755715039.994345 1917530 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -18 } } } inputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -9 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -9 } dim { size: -37 } dim { size: -38 } dim { size: -18 } } }
W0000 00:00:1755715039.994400 1917530 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 224 } dim { size: 224 } dim { size: -19 } } } inputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -10 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "111" frequency: 2000 num_cores: 28 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 110100480 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -10 } dim { size: -39 } dim { size: -40 } dim { size: -19 } } }
slurmstepd: error: *** JOB 267039 ON dgx-06 CANCELLED AT 2025-08-21T02:53:05 ***
